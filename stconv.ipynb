{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entsoe import load_data, get_dap_dataloader\n",
    "import numpy as np\n",
    "from torch_geometric_temporal.nn.attention.stgcn import STConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dap_dataloader(window_size=24, future_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnLayer(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(FullyConnLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(c, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# adapted from Hao Wei\n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self, c, T, n):\n",
    "        super(OutputLayer, self).__init__()\n",
    "        self.tconv1 = nn.Conv2d(c, c, (T, 1), 1, dilation=1, padding=(0, 0))\n",
    "        self.ln = nn.LayerNorm([n, c])\n",
    "        self.tconv2 = nn.Conv2d(c, c, (1, 1), 1, dilation=1, padding=(0, 0))\n",
    "        self.fc = FullyConnLayer(c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_t1 = self.tconv1(x)\n",
    "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        x_t2 = self.tconv2(x_ln)\n",
    "        return self.fc(x_t2)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, window_size, num_nodes):\n",
    "        super(Model, self).__init__()\n",
    "        self.stconv1 = STConv(\n",
    "            num_nodes=10,\n",
    "            in_channels=24,\n",
    "            hidden_channels=16,\n",
    "            out_channels=12,\n",
    "            kernel_size=3,\n",
    "            K=1,\n",
    "        )\n",
    "        self.stconv2 = STConv(\n",
    "            num_nodes=10,\n",
    "            in_channels=12,\n",
    "            hidden_channels=16,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            K=1,\n",
    "        )\n",
    "        # window_size - 2 * num_layers * (kernel_size - 1) = 24 - 2 * 2 * (3 - 1) = 16\n",
    "        T = 24 - 2 * 2 * (3 - 1)\n",
    "        self.output_layer = OutputLayer(8, T, 10)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.stconv1(x, edge_index, edge_weight)\n",
    "        x = self.stconv2(x, edge_index, edge_weight)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.output_layer(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_data = len(data)\n",
    "len_data = 730\n",
    "window_size = 24\n",
    "batch_size = 10\n",
    "model = Model(window_size, 10)\n",
    "model.train()\n",
    "edge_index = data[0].edge_index  # static graph\n",
    "# print(edge_index.shape)\n",
    "criteron = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for i in tqdm(range(0, len_data - window_size - 1)):\n",
    "        optimizer.zero_grad()\n",
    "        window_data = data[i : i + window_size]\n",
    "        X = [d.x for d in window_data]\n",
    "        X = torch.stack(X, dim=0)\n",
    "        # Add a 1 dimension in front as batch dimension\n",
    "        X = X.unsqueeze(0)\n",
    "        # print(X.shape)\n",
    "        edge_weights = [d.edge_attr for d in window_data]\n",
    "        avg_edge_weight = np.mean(edge_weights, axis=0)\n",
    "        edge_weights = torch.tensor(avg_edge_weight, dtype=torch.float32)\n",
    "\n",
    "        y = data[i + window_size].x[:, 0]  # first feature of a node is DAP\n",
    "        # print(y.shape)\n",
    "        y_hat = model(X, edge_index, edge_weights)\n",
    "        # print(y_hat)\n",
    "        # print(y_hat.shape)\n",
    "        y_hat = y_hat.squeeze(0, 1, 3)\n",
    "        # print(y_hat.shape)\n",
    "        # print(y)\n",
    "        loss = criteron(y_hat, y)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch_loss / (len_data - window_size - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_data = len(data)\n",
    "len_data = 730\n",
    "window_size = 24\n",
    "batch_size = 10\n",
    "model = Model(window_size, 10)\n",
    "model.train()\n",
    "for data in dataloader:\n",
    "    edge_index = data[2][0, 0, :, :]\n",
    "    break\n",
    "print(edge_index.shape)\n",
    "criteron = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "for data in tqdm(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    X, edge_weights, _, y = data\n",
    "    print(X.shape)\n",
    "    print(edge_weights.shape)\n",
    "    y_hat = model(X, edge_index, edge_weights).squeeze(1, 3)\n",
    "    # print(y_hat.shape)\n",
    "    # print(y.shape)\n",
    "    loss = criteron(y_hat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
