{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from currency_converter import CurrencyConverter\n",
    "from tqdm import tqdm\n",
    "from config import (\n",
    "    countries,\n",
    "    dap_bidding_zones,\n",
    "    interconnections,\n",
    "    interconnections_edge_matrix,\n",
    ")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "engine = create_engine(os.getenv(\"SQLALCHEMY_DATABASE_URI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = pd.read_sql_table(\"flow_32\", engine)\n",
    "flow_df = flow_df.set_index(\"DateTime\")\n",
    "flow_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CurrencyConverter(fallback_on_missing_rate=True)\n",
    "dap_df = pd.DataFrame()\n",
    "for country_id in countries.keys():\n",
    "    df = pd.read_sql_table(f\"{country_id}_dap\", engine)\n",
    "    if country_id == \"UK\":\n",
    "        # Do currency conversion GBP -> EUR according to day\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "        df[\"EUR\"] = df[\"DateTime\"].apply(lambda x: c.convert(1, \"GBP\", \"EUR\", x))\n",
    "        df.set_index(\"DateTime\", inplace=True)\n",
    "        df[\"0\"] = df[\"0\"] * df[\"EUR\"]\n",
    "        df.drop(columns=[\"EUR\"], inplace=True)\n",
    "        dap_df[country_id] = df\n",
    "    else:\n",
    "        dap_df[country_id] = df.set_index(\"DateTime\")\n",
    "dap_df.ffill(inplace=True)\n",
    "dap_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df = pd.DataFrame()\n",
    "for country_id in countries.keys():\n",
    "    load_df[country_id] = pd.read_sql_table(f\"{country_id}_load\", engine).set_index(\n",
    "        \"DateTime\"\n",
    "    )\n",
    "load_df.ffill(inplace=True)\n",
    "# Fille NaN with mean of the column\n",
    "load_df.fillna(load_df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomass_df = pd.DataFrame()\n",
    "fossil_brown_coal_df = pd.DataFrame()\n",
    "fossil_coal_derived_gas_df = pd.DataFrame()\n",
    "fossil_gas_df = pd.DataFrame()\n",
    "fossil_hard_coal_df = pd.DataFrame()\n",
    "fossil_oil_df = pd.DataFrame()\n",
    "hydro_pumped_storage_df = pd.DataFrame()\n",
    "hydro_run_of_river_and_poundage_df = pd.DataFrame()\n",
    "hydro_water_reservoir_df = pd.DataFrame()\n",
    "nuclear_df = pd.DataFrame()\n",
    "other_df = pd.DataFrame()\n",
    "other_renewable_df = pd.DataFrame()\n",
    "solar_df = pd.DataFrame()\n",
    "waste_df = pd.DataFrame()\n",
    "wind_offshore_df = pd.DataFrame()\n",
    "wind_onshore_df = pd.DataFrame()\n",
    "geothermal_df = pd.DataFrame()\n",
    "fossil_peat_df = pd.DataFrame()\n",
    "\n",
    "gen_types = [\n",
    "    \"Biomass\",\n",
    "    \"Fossil Brown coal/Lignite\",\n",
    "    \"Fossil Coal-derived gas\",\n",
    "    \"Fossil Gas\",\n",
    "    \"Fossil Hard coal\",\n",
    "    \"Fossil Oil\",\n",
    "    \"Hydro Pumped Storage\",\n",
    "    \"Hydro Run-of-river and poundage\",\n",
    "    \"Hydro Water Reservoir\",\n",
    "    \"Nuclear\",\n",
    "    \"Other\",\n",
    "    \"Other renewable\",\n",
    "    \"Solar\",\n",
    "    \"Waste\",\n",
    "    \"Wind Offshore\",\n",
    "    \"Wind Onshore\",\n",
    "    \"Geothermal\",\n",
    "    \"Fossil Peat\",\n",
    "]\n",
    "\n",
    "for country_id in countries.keys():\n",
    "    this_cty_gen_df = pd.read_sql_table(f\"{country_id}_gen\", engine).set_index(\n",
    "        \"DateTime\"\n",
    "    )\n",
    "    biomass_df[country_id] = this_cty_gen_df[\"Biomass\"]\n",
    "    fossil_brown_coal_df[country_id] = this_cty_gen_df[\"Fossil Brown coal/Lignite\"]\n",
    "    fossil_coal_derived_gas_df[country_id] = this_cty_gen_df[\"Fossil Coal-derived gas\"]\n",
    "    fossil_gas_df[country_id] = this_cty_gen_df[\"Fossil Gas\"]\n",
    "    fossil_hard_coal_df[country_id] = this_cty_gen_df[\"Fossil Hard coal\"]\n",
    "    fossil_oil_df[country_id] = this_cty_gen_df[\"Fossil Oil\"]\n",
    "    hydro_pumped_storage_df[country_id] = this_cty_gen_df[\"Hydro Pumped Storage\"]\n",
    "    hydro_run_of_river_and_poundage_df[country_id] = this_cty_gen_df[\n",
    "        \"Hydro Run-of-river and poundage\"\n",
    "    ]\n",
    "    hydro_water_reservoir_df[country_id] = this_cty_gen_df[\"Hydro Water Reservoir\"]\n",
    "    nuclear_df[country_id] = this_cty_gen_df[\"Nuclear\"]\n",
    "    other_df[country_id] = this_cty_gen_df[\"Other\"]\n",
    "    other_renewable_df[country_id] = this_cty_gen_df[\"Other renewable\"]\n",
    "    solar_df[country_id] = this_cty_gen_df[\"Solar\"]\n",
    "    waste_df[country_id] = this_cty_gen_df[\"Waste\"]\n",
    "    wind_offshore_df[country_id] = this_cty_gen_df[\"Wind Offshore\"]\n",
    "    wind_onshore_df[country_id] = this_cty_gen_df[\"Wind Onshore\"]\n",
    "    geothermal_df[country_id] = this_cty_gen_df[\"Geothermal\"]\n",
    "    fossil_peat_df[country_id] = this_cty_gen_df[\"Fossil Peat\"]\n",
    "\n",
    "biomass_df.fillna(0, inplace=True)\n",
    "fossil_brown_coal_df.fillna(0, inplace=True)\n",
    "fossil_coal_derived_gas_df.fillna(0, inplace=True)\n",
    "fossil_gas_df.fillna(0, inplace=True)\n",
    "fossil_hard_coal_df.fillna(0, inplace=True)\n",
    "fossil_oil_df.fillna(0, inplace=True)\n",
    "hydro_pumped_storage_df.fillna(0, inplace=True)\n",
    "hydro_run_of_river_and_poundage_df.fillna(0, inplace=True)\n",
    "hydro_water_reservoir_df.fillna(0, inplace=True)\n",
    "nuclear_df.fillna(0, inplace=True)\n",
    "other_df.fillna(0, inplace=True)\n",
    "other_renewable_df.fillna(0, inplace=True)\n",
    "solar_df.fillna(0, inplace=True)\n",
    "waste_df.fillna(0, inplace=True)\n",
    "wind_offshore_df.fillna(0, inplace=True)\n",
    "wind_onshore_df.fillna(0, inplace=True)\n",
    "geothermal_df.fillna(0, inplace=True)\n",
    "fossil_peat_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43729\n",
      "2015-01-04 23:00:00 2019-12-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "datetime_intersect = (\n",
    "    flow_df.index.intersection(dap_df.index)\n",
    "    .intersection(load_df.index)\n",
    "    .intersection(biomass_df.index)\n",
    "    .intersection(fossil_brown_coal_df.index)\n",
    "    .intersection(fossil_coal_derived_gas_df.index)\n",
    "    .intersection(fossil_gas_df.index)\n",
    "    .intersection(fossil_hard_coal_df.index)\n",
    "    .intersection(fossil_oil_df.index)\n",
    "    .intersection(hydro_pumped_storage_df.index)\n",
    "    .intersection(hydro_run_of_river_and_poundage_df.index)\n",
    "    .intersection(hydro_water_reservoir_df.index)\n",
    "    .intersection(nuclear_df.index)\n",
    "    .intersection(other_df.index)\n",
    "    .intersection(other_renewable_df.index)\n",
    "    .intersection(solar_df.index)\n",
    "    .intersection(waste_df.index)\n",
    "    .intersection(wind_offshore_df.index)\n",
    "    .intersection(wind_onshore_df.index)\n",
    "    .intersection(geothermal_df.index)\n",
    "    .intersection(fossil_peat_df.index)\n",
    ")\n",
    "print(len(datetime_intersect))\n",
    "print(min(datetime_intersect), max(datetime_intersect))\n",
    "# Check if datetime_intersect is monotonically increasing\n",
    "assert all(\n",
    "    datetime_intersect[i] < datetime_intersect[i + 1]\n",
    "    for i in range(len(datetime_intersect) - 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features based on datetime_intersect\n",
    "temporal_hour_df = pd.DataFrame(index=datetime_intersect)\n",
    "temporal_dow_df = pd.DataFrame(index=datetime_intersect)\n",
    "temporal_month_df = pd.DataFrame(index=datetime_intersect)\n",
    "temporal_doy_df = pd.DataFrame(index=datetime_intersect)\n",
    "for country_id in countries.keys():\n",
    "    temporal_hour_df[country_id] = datetime_intersect.hour\n",
    "    temporal_dow_df[country_id] = datetime_intersect.dayofweek\n",
    "    temporal_month_df[country_id] = datetime_intersect.month\n",
    "    temporal_doy_df[country_id] = datetime_intersect.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = flow_df.loc[datetime_intersect]\n",
    "dap_df = dap_df.loc[datetime_intersect]\n",
    "load_df = load_df.loc[datetime_intersect]\n",
    "biomass_df = biomass_df.loc[datetime_intersect]\n",
    "fossil_brown_coal_df = fossil_brown_coal_df.loc[datetime_intersect]\n",
    "fossil_coal_derived_gas_df = fossil_coal_derived_gas_df.loc[datetime_intersect]\n",
    "fossil_gas_df = fossil_gas_df.loc[datetime_intersect]\n",
    "fossil_hard_coal_df = fossil_hard_coal_df.loc[datetime_intersect]\n",
    "fossil_oil_df = fossil_oil_df.loc[datetime_intersect]\n",
    "hydro_pumped_storage_df = hydro_pumped_storage_df.loc[datetime_intersect]\n",
    "hydro_run_of_river_and_poundage_df = hydro_run_of_river_and_poundage_df.loc[\n",
    "    datetime_intersect\n",
    "]\n",
    "hydro_water_reservoir_df = hydro_water_reservoir_df.loc[datetime_intersect]\n",
    "nuclear_df = nuclear_df.loc[datetime_intersect]\n",
    "other_df = other_df.loc[datetime_intersect]\n",
    "other_renewable_df = other_renewable_df.loc[datetime_intersect]\n",
    "solar_df = solar_df.loc[datetime_intersect]\n",
    "waste_df = waste_df.loc[datetime_intersect]\n",
    "wind_offshore_df = wind_offshore_df.loc[datetime_intersect]\n",
    "wind_onshore_df = wind_onshore_df.loc[datetime_intersect]\n",
    "geothermal_df = geothermal_df.loc[datetime_intersect]\n",
    "fossil_peat_df = fossil_peat_df.loc[datetime_intersect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n",
      "(43729, 2, 32)\n"
     ]
    }
   ],
   "source": [
    "edges = np.array(interconnections_edge_matrix)\n",
    "print(edges.shape)\n",
    "# Map edge names to indices\n",
    "edge_names = np.unique(edges)\n",
    "edge_map = {edge: i for i, edge in enumerate(edge_names)}\n",
    "edge_indices = np.array([edge_map[edge] for edge in edges.flatten()]).reshape(\n",
    "    edges.shape\n",
    ")\n",
    "# Repeat edge indices for each datetime\n",
    "edge_indices = np.repeat(\n",
    "    edge_indices[np.newaxis, :, :],\n",
    "    len(datetime_intersect),\n",
    "    axis=0,\n",
    ")\n",
    "print(edge_indices.shape)\n",
    "n_edges = edges.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43729, 32, 1)\n",
      "(43729, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Edge labels (flow) of shape (n_datetime, n_edges, 1)\n",
    "edge_labels = np.array(flow_df)\n",
    "# print(edge_labels.shape)\n",
    "edge_labels = np.reshape(\n",
    "    edge_labels, (len(datetime_intersect), edge_labels.shape[1], 1)\n",
    ")\n",
    "print(edge_labels.shape)\n",
    "edge_attributes = np.copy(edge_labels)\n",
    "print(edge_attributes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43729, 10, 24)\n",
      "[3.656000e+01 1.003953e+04 2.311300e+02 0.000000e+00 0.000000e+00\n",
      " 1.791710e+03 4.368500e+02 0.000000e+00 0.000000e+00 3.596000e+01\n",
      " 0.000000e+00 3.904350e+03 6.016400e+02 0.000000e+00 0.000000e+00\n",
      " 2.690100e+02 4.937000e+01 2.415900e+02 0.000000e+00 0.000000e+00\n",
      " 2.300000e+01 6.000000e+00 1.000000e+00 4.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Node features (dap, load) of shape (n_datetime, n_nodes, n_node_features)\n",
    "node_features = np.stack(\n",
    "    [\n",
    "        dap_df.to_numpy(),\n",
    "        load_df.to_numpy(),\n",
    "        biomass_df.to_numpy(),\n",
    "        fossil_brown_coal_df.to_numpy(),\n",
    "        fossil_coal_derived_gas_df.to_numpy(),\n",
    "        fossil_gas_df.to_numpy(),\n",
    "        fossil_hard_coal_df.to_numpy(),\n",
    "        fossil_oil_df.to_numpy(),\n",
    "        hydro_pumped_storage_df.to_numpy(),\n",
    "        hydro_run_of_river_and_poundage_df.to_numpy(),\n",
    "        hydro_water_reservoir_df.to_numpy(),\n",
    "        nuclear_df.to_numpy(),\n",
    "        other_df.to_numpy(),\n",
    "        other_renewable_df.to_numpy(),\n",
    "        solar_df.to_numpy(),\n",
    "        waste_df.to_numpy(),\n",
    "        wind_offshore_df.to_numpy(),\n",
    "        wind_onshore_df.to_numpy(),\n",
    "        geothermal_df.to_numpy(),\n",
    "        fossil_peat_df.to_numpy(),\n",
    "        temporal_hour_df.to_numpy(),\n",
    "        temporal_dow_df.to_numpy(),\n",
    "        temporal_month_df.to_numpy(),\n",
    "        temporal_doy_df.to_numpy(),\n",
    "    ],\n",
    "    axis=-1,\n",
    ")\n",
    "print(node_features.shape)\n",
    "print(node_features[0, 0, :])\n",
    "# print(node_features)\n",
    "n_nodes = node_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    len(datetime_intersect)\n",
    "    == edge_indices.shape[0]\n",
    "    == edge_labels.shape[0]\n",
    "    == edge_attributes.shape[0]\n",
    "    == node_features.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-04 23:00:00\n",
      "[[0 0 0 0 3 3 3 4 4 4 4 2 2 2 2 2 5 6 6 7 7 7 7 7 8 8 1 1 9 9 9 9]\n",
      " [4 6 7 9 2 7 8 0 2 1 9 3 4 6 7 1 9 0 2 0 3 2 8 9 3 7 4 2 0 4 5 7]]\n",
      "[[   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [1315.79]\n",
      " [  52.  ]\n",
      " [ 617.  ]\n",
      " [ 279.  ]\n",
      " [1433.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [3205.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [2106.86]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [ 964.  ]\n",
      " [   0.  ]\n",
      " [ 704.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [ 169.19]\n",
      " [   0.  ]]\n",
      "[[   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [1315.79]\n",
      " [  52.  ]\n",
      " [ 617.  ]\n",
      " [ 279.  ]\n",
      " [1433.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [3205.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [2106.86]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [ 964.  ]\n",
      " [   0.  ]\n",
      " [ 704.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [   0.  ]\n",
      " [ 169.19]\n",
      " [   0.  ]]\n",
      "[[3.65600000e+01 1.00395300e+04 2.31130000e+02 0.00000000e+00\n",
      "  0.00000000e+00 1.79171000e+03 4.36850000e+02 0.00000000e+00\n",
      "  0.00000000e+00 3.59600000e+01 0.00000000e+00 3.90435000e+03\n",
      "  6.01640000e+02 0.00000000e+00 0.00000000e+00 2.69010000e+02\n",
      "  4.93700000e+01 2.41590000e+02 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [2.86250000e+01 3.19045000e+03 6.92000000e+01 0.00000000e+00\n",
      "  0.00000000e+00 4.92090000e+02 1.42000000e+03 2.12100000e+01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.75330000e+02\n",
      "  7.71120000e+02 1.57288000e+03 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [3.65600000e+01 6.26100000e+04 1.97000000e+02 0.00000000e+00\n",
      "  0.00000000e+00 2.43500000e+03 1.48400000e+03 2.61000000e+02\n",
      "  1.30400000e+03 5.27100000e+03 8.19000000e+02 5.64990000e+04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.78000000e+02\n",
      "  0.00000000e+00 1.05700000e+03 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [2.23400000e+01 4.66678700e+04 3.95028750e+03 1.60414725e+04\n",
      "  0.00000000e+00 9.87150000e+02 2.20156250e+03 1.91917500e+02\n",
      "  6.73325000e+01 1.65707250e+03 2.30700000e+01 1.09347475e+04\n",
      "  3.31460000e+02 1.21310000e+02 0.00000000e+00 5.23300000e+02\n",
      "  4.78020000e+02 1.27166450e+04 1.07125000e+01 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [4.91400000e+01 2.90401500e+03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.20695000e+02 4.78655000e+02 6.00000000e-02\n",
      "  1.52050000e+01 1.54355000e+02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.73090000e+02 0.00000000e+00 3.32240000e+02\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [2.23400000e+01 4.37000000e+02 5.63500000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.79500000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.68500000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.20625000e+01\n",
      "  0.00000000e+00 1.57000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [3.65600000e+01 1.14760075e+04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.66168500e+03 1.17240000e+03 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.88195000e+02\n",
      "  5.09762000e+03 0.00000000e+00 0.00000000e+00 1.20547500e+02\n",
      "  5.32725000e+01 1.28867500e+02 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [2.85380000e+01 1.67024600e+04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.72610000e+02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.18922000e+03 1.49508300e+04 0.00000000e+00\n",
      "  1.64000000e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.73350000e+02 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [3.78000000e+01 7.01962000e+03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.00000000e-02 0.00000000e+00\n",
      "  0.00000000e+00 8.60000000e-01 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]\n",
      " [5.48222052e+01 2.88430000e+04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.34050000e+01 3.67270000e+02 0.00000000e+00 0.00000000e+00\n",
      "  2.30000000e+01 6.00000000e+00 1.00000000e+00 4.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Print a snapshot of the graph data\n",
    "idx = 0\n",
    "print(datetime_intersect[idx])\n",
    "print(edge_indices[idx])\n",
    "print(edge_labels[idx])\n",
    "print(edge_attributes[idx])\n",
    "print(node_features[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATv2Conv.html\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gat = GATv2Conv(\n",
    "            (-1, -1),\n",
    "            hidden_channels,\n",
    "            add_self_loops=False,\n",
    "            heads=num_heads_GAT,\n",
    "            edge_dim=edge_dim_GAT,\n",
    "        )\n",
    "        self.norm = BatchNorm1d(\n",
    "            hidden_channels,\n",
    "            momentum=momentum_GAT,\n",
    "            affine=False,\n",
    "            track_running_stats=False,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_p_GAT)\n",
    "\n",
    "    def forward(self, x, edge_indices, edge_attrs):\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm(x)\n",
    "        nodes_embedds = self.gat(x, edge_indices, edge_attrs)\n",
    "        nodes_embedds = F.leaky_relu(nodes_embedds, negative_slope=0.1)\n",
    "        return nodes_embedds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model,\n",
    "        num_heads_TR,\n",
    "        num_encoder_layers_TR,\n",
    "        num_decoder_layers_TR,\n",
    "        dropout_p_TR,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads_TR,\n",
    "            num_decoder_layers=num_encoder_layers_TR,\n",
    "            num_encoder_layers=num_decoder_layers_TR,\n",
    "            dropout=dropout_p_TR,\n",
    "        )\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src = self.pos_encoder(src)\n",
    "        trg = self.pos_encoder(trg)\n",
    "        temporal_node_embeddings = self.transformer(src, trg)\n",
    "        return temporal_node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDecoder(nn.Module):\n",
    "    def __init__(self, hidden_channels, num_heads_GAT, num_edges, num_nodes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(\n",
    "            num_nodes * hidden_channels * num_heads_GAT, hidden_channels\n",
    "        )\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_edges)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.1)\n",
    "        x = self.lin2(x)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        num_heads_GAT,\n",
    "        dropout_p_GAT,\n",
    "        edge_dim_GAT,\n",
    "        momentum_GAT,\n",
    "        dim_model,\n",
    "        num_heads_TR,\n",
    "        num_encoder_layers_TR,\n",
    "        num_decoder_layers_TR,\n",
    "        dropout_p_TR,\n",
    "        n_edges,\n",
    "        n_nodes,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(\n",
    "            hidden_channels, num_heads_GAT, dropout_p_GAT, edge_dim_GAT, momentum_GAT\n",
    "        )  # node embedding with GAT\n",
    "        self.transformer = Transformer(\n",
    "            dim_model,\n",
    "            num_heads_TR,\n",
    "            num_encoder_layers_TR,\n",
    "            num_decoder_layers_TR,\n",
    "            dropout_p_TR,\n",
    "        )\n",
    "        self.decoder = EdgeDecoder(hidden_channels, num_heads_GAT, n_edges, n_nodes)\n",
    "\n",
    "    def forward(self, x, edge_indices, edge_attrs):\n",
    "        src_embedds = []\n",
    "        for i in range(x.shape[0]):\n",
    "            src_embedds.append(self.encoder(x[i], edge_indices[i], edge_attrs[i]))\n",
    "        src_embedds = torch.stack(src_embedds)\n",
    "        trg_embedds = src_embedds[-1].unsqueeze(0)\n",
    "        temporal_node_embedds = self.transformer(src_embedds, trg_embedds)\n",
    "        temporal_node_embedds = temporal_node_embedds.squeeze(0)\n",
    "        edge_predictions = self.decoder(temporal_node_embedds)\n",
    "        return edge_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, node_features, edge_indices, edge_attributes, edge_labels, window_size=24\n",
    "    ):\n",
    "        assert (\n",
    "            len(node_features)\n",
    "            == len(edge_indices)\n",
    "            == len(edge_attributes)\n",
    "            == len(edge_labels)\n",
    "        )\n",
    "        self.n_samples = len(node_features)\n",
    "\n",
    "        self.x = torch.tensor(node_features, dtype=torch.float)\n",
    "        self.edge_indices = torch.tensor(edge_indices, dtype=torch.long)\n",
    "        self.edge_attrs = torch.tensor(edge_attributes, dtype=torch.float)\n",
    "        self.y = torch.tensor(edge_labels, dtype=torch.float)\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x[idx : idx + self.window_size],\n",
    "            self.edge_indices[idx : idx + self.window_size],\n",
    "            self.edge_attrs[idx : idx + self.window_size],\n",
    "            self.y[idx + self.window_size],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43705\n"
     ]
    }
   ],
   "source": [
    "dataset = GraphDataset(node_features, edge_indices, edge_attributes, edge_labels)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, num_epochs, lr):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_sum = None\n",
    "        for x, edge_indices, edge_attrs, y in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = np.squeeze(x)\n",
    "            edge_indices = np.squeeze(edge_indices)\n",
    "            edge_attrs = np.squeeze(edge_attrs)\n",
    "            y = np.squeeze(y)\n",
    "            # print(x.shape, edge_indices.shape, edge_attrs.shape, y.shape)\n",
    "\n",
    "            x = x.to(device)\n",
    "            edge_indices = edge_indices.to(device)\n",
    "            edge_attrs = edge_attrs.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x, edge_indices, edge_attrs)\n",
    "            y_pred = y_pred.view((-1, 1))\n",
    "            loss = criterion(y_pred, y)\n",
    "            if loss_sum is None:\n",
    "                loss_sum = loss\n",
    "            else:\n",
    "                loss_sum += loss\n",
    "            loss_sum.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_sum = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "  0%|          | 0/43705 [00:00<?, ?it/s]c:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 60/43705 [00:03<43:26, 16.75it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 17\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[0;32m      3\u001b[0m     hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m      4\u001b[0m     num_heads_GAT\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     n_nodes\u001b[38;5;241m=\u001b[39mn_nodes,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# train(model, snapshots[8760:17000], window_size=24, num_epochs=10000, lr=0.001)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, num_epochs, lr)\u001b[0m\n\u001b[0;32m     19\u001b[0m edge_attrs \u001b[38;5;241m=\u001b[39m edge_attrs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mview((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y)\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[39], line 36\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x, edge_indices, edge_attrs)\u001b[0m\n\u001b[0;32m     34\u001b[0m src_embedds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(src_embedds)\n\u001b[0;32m     35\u001b[0m trg_embedds \u001b[38;5;241m=\u001b[39m src_embedds[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m temporal_node_embedds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_embedds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_embedds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m temporal_node_embedds \u001b[38;5;241m=\u001b[39m temporal_node_embedds\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     38\u001b[0m edge_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(temporal_node_embedds)\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, trg)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, trg):\n\u001b[1;32m---> 21\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     trg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(trg)\n\u001b[0;32m     23\u001b[0m     temporal_node_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(src, trg)\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 17\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe[: x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m(x)\n",
      "File \u001b[1;32mc:\\Users\\lemuelkl\\anaconda3\\envs\\euics\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1673\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1684\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(\n",
    "    hidden_channels=64,\n",
    "    num_heads_GAT=4,\n",
    "    dropout_p_GAT=0.1,\n",
    "    edge_dim_GAT=1,  # edge attributes\n",
    "    momentum_GAT=0.1,\n",
    "    dim_model=64 * 4,  # hidden_channels * num_heads_GAT\n",
    "    num_heads_TR=4,\n",
    "    num_encoder_layers_TR=6,\n",
    "    num_decoder_layers_TR=6,\n",
    "    dropout_p_TR=0.1,\n",
    "    n_edges=n_edges,\n",
    "    n_nodes=n_nodes,\n",
    ")\n",
    "# train(model, snapshots[8760:17000], window_size=24, num_epochs=10000, lr=0.001)\n",
    "train(model, dataloader, num_epochs=100, lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
